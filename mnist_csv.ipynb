{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B0IZlSLvZeMC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
        "                            precision_score, recall_score, f1_score,confusion_matrix,roc_auc_score\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhMm16_wbCE5"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dzbo8LLFZ_y-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Deep Learning/Mnist_csv/mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Deep Learning/Mnist_csv/mnist_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRQNSRrfabs7",
        "outputId": "313f5a71-d590-4992-9230-415539ae10ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 785), (10000, 785))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COP5zbhObGDH"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yts2K25iah4D",
        "outputId": "0f2f2be9-417d-462f-f697-cd8d636acde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 70000\n",
            "Number of features: 784\n",
            "Target classes: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "0    6903\n",
            "1    7877\n",
            "2    6990\n",
            "3    7141\n",
            "4    6824\n",
            "5    6313\n",
            "6    6876\n",
            "7    7293\n",
            "8    6825\n",
            "9    6958\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Combine train and test for initial exploration\n",
        "df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"Number of features:\", df.shape[1] - 1)  # minus the label column\n",
        "print(\"Target classes:\", sorted(df['label'].unique()))\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['label'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OotWzAC5bey8"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "gFLCvGYjbcsD",
        "outputId": "36cce527-73e0-4f45-9ca6-c69969d57c60"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display sample images\n",
        "def plot_digits(data, num_images=10):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    for i, ax in enumerate(axes):\n",
        "        img = data.iloc[i, 1:].values.reshape(28, 28)\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_title(f\"Label: {data.iloc[i, 0]}\")\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Plot first 10 digits from training set\n",
        "plot_digits(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNW7dhk4b3bt"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tbWSY_ZIb7hi"
      },
      "outputs": [],
      "source": [
        "# Separate features and labels\n",
        "X_train = train_df.drop('label', axis=1).values\n",
        "y_train = train_df['label'].values\n",
        "X_test = test_df.drop('label', axis=1).values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpwCzcFGcFrM",
        "outputId": "cc597ba5-6d43-444a-ac22-a53e3a60a929"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bxY0mvch5M"
      },
      "source": [
        "### Model Training & Evluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rTsXEaYcKeC",
        "outputId": "be20d14a-b588-4ce6-dc75-df8a82820379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logisitic Regression\n",
            "Model performance for Training set\n",
            "- Accuracy: 0.9351\n",
            "- F1 score: 0.9350\n",
            "- Precision: 0.9349\n",
            "- Recall: 0.9351\n",
            "- Confusion Matrix:\n",
            "[[5768    1   13    8   13   40   33    8   35    4]\n",
            " [   1 6581   29   19    6   26    3   13   54   10]\n",
            " [  25   50 5444   91   62   24   59   57  122   24]\n",
            " [  17   24  118 5558    7  184   16   48  116   43]\n",
            " [  11   24   24    9 5506    7   49   19   34  159]\n",
            " [  48   19   38  146   45 4883   75   18  112   37]\n",
            " [  27   13   38    1   35   65 5710    5   21    3]\n",
            " [   8   20   62   23   41   10    4 5917   16  164]\n",
            " [  26   96   56  130   24  135   37   17 5275   55]\n",
            " [  21   26   14   67  130   33    3  149   45 5461]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9257\n",
            "- F1 score: 0.9256\n",
            "- Precision: 0.9256\n",
            "- Recall: 0.9257\n",
            "- Confusion Matrix:\n",
            "[[ 959    0    0    3    1    7    5    4    1    0]\n",
            " [   0 1111    4    2    0    2    3    2   11    0]\n",
            " [   6    9  926   16    9    4   13    6   39    4]\n",
            " [   4    1   18  917    1   22    4   11   25    7]\n",
            " [   1    1    7    3  914    0   10    4   10   32]\n",
            " [  10    2    3   34    7  783   14    6   29    4]\n",
            " [   9    3    8    2    7   14  912    2    1    0]\n",
            " [   1    8   24    5    7    1    0  950    3   29]\n",
            " [   9   11    8   23    7   25   12    7  860   12]\n",
            " [   9    8    0   11   24    6    0   19    7  925]]\n",
            "===================================\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "Model performance for Training set\n",
            "- Accuracy: 1.0000\n",
            "- F1 score: 1.0000\n",
            "- Precision: 1.0000\n",
            "- Recall: 1.0000\n",
            "- Confusion Matrix:\n",
            "[[5923    0    0    0    0    0    0    0    0    0]\n",
            " [   0 6742    0    0    0    0    0    0    0    0]\n",
            " [   0    0 5958    0    0    0    0    0    0    0]\n",
            " [   0    0    0 6131    0    0    0    0    0    0]\n",
            " [   0    0    0    0 5842    0    0    0    0    0]\n",
            " [   0    0    0    0    0 5421    0    0    0    0]\n",
            " [   0    0    0    0    0    0 5918    0    0    0]\n",
            " [   0    0    0    0    0    0    0 6265    0    0]\n",
            " [   0    0    0    0    0    0    0    0 5851    0]\n",
            " [   0    0    0    0    0    0    0    0    0 5949]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.8754\n",
            "- F1 score: 0.8753\n",
            "- Precision: 0.8753\n",
            "- Recall: 0.8754\n",
            "- Confusion Matrix:\n",
            "[[ 914    1    7    4    6    9   16    5    8   10]\n",
            " [   0 1084    9    8    2    9    5    3   14    1]\n",
            " [  13   11  887   29   15    6    9   24   30    8]\n",
            " [   7    8   34  861    8   40    3    6   17   26]\n",
            " [   8    4   11    6  858    5   18   10   20   42]\n",
            " [  15    8    5   39    6  740   25    6   32   16]\n",
            " [  21    5   11    9   23   15  846    3   20    5]\n",
            " [   2    7   21   24   12    5    3  925    9   20]\n",
            " [   8    9   33   34   21   32   14   12  785   26]\n",
            " [  14    5   10   22   45   10    6   20   23  854]]\n",
            "===================================\n",
            "\n",
            "\n",
            "SVC\n",
            "Model performance for Training set\n",
            "- Accuracy: 0.9899\n",
            "- F1 score: 0.9899\n",
            "- Precision: 0.9899\n",
            "- Recall: 0.9899\n",
            "- Confusion Matrix:\n",
            "[[5902    1    1    1    3    2    4    0    5    4]\n",
            " [   1 6705   11    1    4    0    1   10    3    6]\n",
            " [   5    5 5910    3   10    0    1   15    6    3]\n",
            " [   1    2   22 6032    0   23    1   18   20   12]\n",
            " [   2    9    5    0 5781    0    9    3    2   31]\n",
            " [   5    1    5   22    6 5361   13    0    4    4]\n",
            " [   8    2    1    0    5    4 5894    0    4    0]\n",
            " [   2   20   17    0   17    0    0 6182    3   24]\n",
            " [   3   14    9    8    6   12    2    5 5786    6]\n",
            " [   8    8    1   13   36    5    1   27    8 5842]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9792\n",
            "- F1 score: 0.9792\n",
            "- Precision: 0.9792\n",
            "- Recall: 0.9792\n",
            "- Confusion Matrix:\n",
            "[[ 973    0    1    0    0    2    1    1    2    0]\n",
            " [   0 1126    3    1    0    1    1    1    2    0]\n",
            " [   6    1 1006    2    1    0    2    7    6    1]\n",
            " [   0    0    2  995    0    2    0    5    5    1]\n",
            " [   0    0    5    0  961    0    3    0    2   11]\n",
            " [   2    0    0    9    0  871    4    1    4    1]\n",
            " [   6    2    0    0    2    3  944    0    1    0]\n",
            " [   0    6   11    1    1    0    0  996    2   11]\n",
            " [   3    0    2    6    3    2    2    3  950    3]\n",
            " [   3    4    1    7   10    2    1    7    4  970]]\n",
            "===================================\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models={\n",
        "    \"Logisitic Regression\":LogisticRegression(),\n",
        "    \"Decision Tree\":DecisionTreeClassifier(),\n",
        "    \"SVC\": SVC()\n",
        "}\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Training set performance\n",
        "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "    model_train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
        "    model_train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
        "    model_train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "    # Test set performance\n",
        "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "    model_test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "    model_test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "    model_test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "    print(list(models.keys())[i])\n",
        "\n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
        "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
        "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
        "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
        "    print('- Confusion Matrix:')\n",
        "    print(model_train_conf_matrix)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print('Model performance for Test set')\n",
        "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
        "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
        "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
        "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
        "    print('- Confusion Matrix:')\n",
        "    print(model_test_conf_matrix)\n",
        "\n",
        "\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D8yCZVsZgNw9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-84JICkFdJgv"
      },
      "source": [
        "### Hyperparameter Tuning With RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jB2kiXS0ctXz"
      },
      "outputs": [],
      "source": [
        "logistic_params = {\n",
        "        'C': [0.1, 1],\n",
        "        'penalty': ['l2', 'none'],\n",
        "        'solver': ['lbfgs'],\n",
        "        'max_iter': [100, 200],\n",
        "        'multi_class': ['auto']\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': [0.1, 1],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale'],\n",
        "}\n",
        "\n",
        "dt_params = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': [None, 'sqrt']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NQ9slzPZe0Zk"
      },
      "outputs": [],
      "source": [
        "# Models list for Hyperparameter tuning\n",
        "randomcv_models = [\n",
        "    (\"Logistic Regression\", LogisticRegression(), logistic_params),\n",
        "    (\"SVM\", SVC(), svm_params),\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(), dt_params)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqmt9PmSe3OX",
        "outputId": "db06c070-7fb3-42e3-8fb2-7b8a5f0e1dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting RandomizedSearchCV for Logistic Regression...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 8 is smaller than n_iter=100. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "12 fits failed out of a total of 24.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.91931667        nan 0.9194            nan 0.91813333        nan\n",
            " 0.91725           nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters for Logistic Regression:\n",
            "{'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'auto', 'max_iter': 200, 'C': 0.1}\n",
            "\n",
            "Starting RandomizedSearchCV for SVM...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=100. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters for SVM:\n",
            "{'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n",
            "\n",
            "Starting RandomizedSearchCV for Decision Tree...\n",
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 48 is smaller than n_iter=100. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best parameters for Decision Tree:\n",
            "{'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': None, 'criterion': 'entropy'}\n",
            "\n",
            "================= Final Best Parameters =================\n",
            "\n",
            "---------------- Best Params for Logistic Regression -------------------\n",
            "{'solver': 'lbfgs', 'penalty': 'l2', 'multi_class': 'auto', 'max_iter': 200, 'C': 0.1}\n",
            "\n",
            "---------------- Best Params for SVM -------------------\n",
            "{'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n",
            "\n",
            "---------------- Best Params for Decision Tree -------------------\n",
            "{'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': None, 'criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store best parameters\n",
        "model_param = {}\n",
        "\n",
        "for name, model, params in randomcv_models:\n",
        "    print(f\"\\nStarting RandomizedSearchCV for {name}...\")\n",
        "    random = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=params,\n",
        "        n_iter=100,\n",
        "        cv=3,\n",
        "        verbose=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    random.fit(X_train, y_train)\n",
        "    model_param[name] = random.best_params_\n",
        "\n",
        "    print(f\"\\nBest parameters for {name}:\")\n",
        "    print(random.best_params_)\n",
        "\n",
        "# Print all best parameters\n",
        "print(\"\\n================= Final Best Parameters =================\")\n",
        "for model_name in model_param:\n",
        "    print(f\"\\n---------------- Best Params for {model_name} -------------------\")\n",
        "    print(model_param[model_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QuWZ34tahbpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea552828-7ea9-4201-ed5c-4ccaade4178a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logisitic Regression\n",
            "Model performance for Training set\n",
            "- Accuracy: 0.9322\n",
            "- F1 score: 0.9321\n",
            "- Precision: 0.9320\n",
            "- Recall: 0.9322\n",
            "- Confusion Matrix:\n",
            "[[5758    1   18   10   11   41   37    7   36    4]\n",
            " [   1 6578   33   16    6   27    3   11   56   11]\n",
            " [  27   56 5415   88   66   25   60   67  128   26]\n",
            " [  17   26  121 5543    5  188   19   52  109   51]\n",
            " [  13   26   27    8 5491    7   51   13   33  173]\n",
            " [  49   26   39  151   51 4858   80   18  103   46]\n",
            " [  29   14   35    1   35   68 5707    3   24    2]\n",
            " [  11   26   58   21   45   11    4 5906   16  167]\n",
            " [  30  110   59  134   23  135   38   16 5240   66]\n",
            " [  23   30   15   70  138   33    2  159   43 5436]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9258\n",
            "- F1 score: 0.9256\n",
            "- Precision: 0.9257\n",
            "- Recall: 0.9258\n",
            "- Confusion Matrix:\n",
            "[[ 958    0    2    3    0    7    5    4    1    0]\n",
            " [   0 1113    2    2    0    1    4    2   11    0]\n",
            " [   6    8  927   15    8    3   13    8   37    7]\n",
            " [   3    1   15  921    0   26    3   11   21    9]\n",
            " [   1    2    5    2  918    0   10    3   10   31]\n",
            " [  10    2    2   36    9  775   15    8   30    5]\n",
            " [  10    3    6    2    8   14  911    2    2    0]\n",
            " [   1    8   23    7    9    1    0  948    1   30]\n",
            " [   6   10    7   20    9   24   11    9  867   11]\n",
            " [  11    8    1    8   25    7    0   22    7  920]]\n",
            "===================================\n",
            "\n",
            "\n",
            "Decision Tree\n",
            "Model performance for Training set\n",
            "- Accuracy: 0.9884\n",
            "- F1 score: 0.9884\n",
            "- Precision: 0.9884\n",
            "- Recall: 0.9884\n",
            "- Confusion Matrix:\n",
            "[[5905    1    2    1    0    2    2    0    8    2]\n",
            " [   5 6721    4    2    2    2    1    0    3    2]\n",
            " [  11    6 5905    7    2    1    7    6    8    5]\n",
            " [   8   13   20 6064    2    4    4    3    8    5]\n",
            " [   9    5   10   14 5776    5    6    4    5    8]\n",
            " [  19    6   15   21    6 5330    6    3   12    3]\n",
            " [  11    5   11   11   10   14 5847    2    6    1]\n",
            " [   8   12   14   16   11    3    4 6190    4    3]\n",
            " [  11   15   24   20   11   19   14   14 5716    7]\n",
            " [   5    4   12   15   19   13    5   10   16 5850]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.8859\n",
            "- F1 score: 0.8858\n",
            "- Precision: 0.8859\n",
            "- Recall: 0.8859\n",
            "- Confusion Matrix:\n",
            "[[ 913    2    8    4    3   19   13    3   10    5]\n",
            " [   0 1103    8    3    1    6    4    3    5    2]\n",
            " [   5    3  915   22   11   11   18   18   22    7]\n",
            " [   8    9   26  865    7   42    5   12   20   16]\n",
            " [   6    4   19    8  859    8   16    9   18   35]\n",
            " [  15    7    9   36    5  753   20    3   25   19]\n",
            " [  21    6    9    6   22   20  860    4    8    2]\n",
            " [   2   12   33   18   13    6    2  920    5   17]\n",
            " [  10    5   20   43   24   20   12    7  811   22]\n",
            " [  10    6   10   24   35   20    3   19   22  860]]\n",
            "===================================\n",
            "\n",
            "\n",
            "SVC\n",
            "Model performance for Training set\n",
            "- Accuracy: 0.9899\n",
            "- F1 score: 0.9899\n",
            "- Precision: 0.9899\n",
            "- Recall: 0.9899\n",
            "- Confusion Matrix:\n",
            "[[5902    1    1    1    3    2    4    0    5    4]\n",
            " [   1 6705   11    1    4    0    1   10    3    6]\n",
            " [   5    5 5910    3   10    0    1   15    6    3]\n",
            " [   1    2   22 6032    0   23    1   18   20   12]\n",
            " [   2    9    5    0 5781    0    9    3    2   31]\n",
            " [   5    1    5   22    6 5361   13    0    4    4]\n",
            " [   8    2    1    0    5    4 5894    0    4    0]\n",
            " [   2   20   17    0   17    0    0 6182    3   24]\n",
            " [   3   14    9    8    6   12    2    5 5786    6]\n",
            " [   8    8    1   13   36    5    1   27    8 5842]]\n",
            "----------------------------------\n",
            "Model performance for Test set\n",
            "- Accuracy: 0.9792\n",
            "- F1 score: 0.9792\n",
            "- Precision: 0.9792\n",
            "- Recall: 0.9792\n",
            "- Confusion Matrix:\n",
            "[[ 973    0    1    0    0    2    1    1    2    0]\n",
            " [   0 1126    3    1    0    1    1    1    2    0]\n",
            " [   6    1 1006    2    1    0    2    7    6    1]\n",
            " [   0    0    2  995    0    2    0    5    5    1]\n",
            " [   0    0    5    0  961    0    3    0    2   11]\n",
            " [   2    0    0    9    0  871    4    1    4    1]\n",
            " [   6    2    0    0    2    3  944    0    1    0]\n",
            " [   0    6   11    1    1    0    0  996    2   11]\n",
            " [   3    0    2    6    3    2    2    3  950    3]\n",
            " [   3    4    1    7   10    2    1    7    4  970]]\n",
            "===================================\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models={\n",
        "    \"Logisitic Regression\":LogisticRegression(solver='lbfgs',\n",
        "        penalty='l2',\n",
        "        multi_class='auto',\n",
        "        max_iter=200,\n",
        "        C=0.1),\n",
        "    \"Decision Tree\":DecisionTreeClassifier( min_samples_split=5,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=None,\n",
        "        max_depth=None,\n",
        "        criterion='entropy'),\n",
        "    \"SVC\": SVC(kernel='rbf',\n",
        "        gamma='scale',\n",
        "        C=1)\n",
        "}\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Training set performance\n",
        "    model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
        "    model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
        "    model_train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
        "    model_train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
        "    model_train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "    # Test set performance\n",
        "    model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
        "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
        "    model_test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "    model_test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "    model_test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "    print(list(models.keys())[i])\n",
        "\n",
        "    print('Model performance for Training set')\n",
        "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
        "    print('- F1 score: {:.4f}'.format(model_train_f1))\n",
        "    print('- Precision: {:.4f}'.format(model_train_precision))\n",
        "    print('- Recall: {:.4f}'.format(model_train_recall))\n",
        "    print('- Confusion Matrix:')\n",
        "    print(model_train_conf_matrix)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print('Model performance for Test set')\n",
        "    print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
        "    print('- F1 score: {:.4f}'.format(model_test_f1))\n",
        "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
        "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
        "    print('- Confusion Matrix:')\n",
        "    print(model_test_conf_matrix)\n",
        "\n",
        "\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyj50HgVhdPF"
      },
      "source": [
        "### Testing Evaluation with Bootstrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JQebGUvWiVc0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def bootstrap_evaluation(model, X_test, y_test, n_iterations=100):\n",
        "    \"\"\"\n",
        "    Perform bootstrap evaluation of a model and compute 95% confidence intervals\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': [],\n",
        "        'roc_auc': []\n",
        "    }\n",
        "\n",
        "    has_proba = hasattr(model, \"predict_proba\")\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Resample with replacement\n",
        "        X_resampled, y_resampled = resample(X_test, y_test, replace=True)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = model.predict(X_resampled)\n",
        "\n",
        "        # Metrics\n",
        "        metrics['accuracy'].append(accuracy_score(y_resampled, y_pred))\n",
        "        metrics['precision'].append(precision_score(y_resampled, y_pred, average='weighted'))\n",
        "        metrics['recall'].append(recall_score(y_resampled, y_pred, average='weighted'))\n",
        "        metrics['f1'].append(f1_score(y_resampled, y_pred, average='weighted'))\n",
        "\n",
        "        # ROC AUC only if possible\n",
        "        if has_proba:\n",
        "            y_proba = model.predict_proba(X_resampled)\n",
        "            metrics['roc_auc'].append(roc_auc_score(y_resampled, y_proba, multi_class='ovr'))\n",
        "\n",
        "    # Remove ROC AUC if we couldn't compute it\n",
        "    if not has_proba:\n",
        "        metrics.pop('roc_auc')\n",
        "\n",
        "    # Statistics\n",
        "    results = {}\n",
        "    for metric, values in metrics.items():\n",
        "        mean_score = np.mean(values)\n",
        "        std_dev = np.std(values)\n",
        "        ci_lower = np.percentile(values, 2.5)\n",
        "        ci_upper = np.percentile(values, 97.5)\n",
        "\n",
        "        results[metric] = {\n",
        "            'mean': mean_score,\n",
        "            'std': std_dev,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper\n",
        "        }\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-Rc7asD_itrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2faa9b37-1839-44d2-8ab9-8910fe15dc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running bootstrap evaluation for Logisitic Regression...\n",
            "\n",
            "Running bootstrap evaluation for Decision Tree...\n",
            "\n",
            "Running bootstrap evaluation for SVC...\n",
            "\n",
            "================ Bootstrap Evaluation Results ================\n",
            "\n",
            "----- Logisitic Regression -----\n",
            "ACCURACY  : 0.9256  0.0025\n",
            "          95% CI: [0.9207, 0.9300]\n",
            "PRECISION : 0.9256  0.0025\n",
            "          95% CI: [0.9207, 0.9302]\n",
            "RECALL    : 0.9256  0.0025\n",
            "          95% CI: [0.9207, 0.9300]\n",
            "F1        : 0.9254  0.0025\n",
            "          95% CI: [0.9206, 0.9299]\n",
            "ROC_AUC   : 0.9941  0.0004\n",
            "          95% CI: [0.9932, 0.9948]\n",
            "\n",
            "----- Decision Tree -----\n",
            "ACCURACY  : 0.8858  0.0034\n",
            "          95% CI: [0.8796, 0.8925]\n",
            "PRECISION : 0.8859  0.0034\n",
            "          95% CI: [0.8798, 0.8926]\n",
            "RECALL    : 0.8858  0.0034\n",
            "          95% CI: [0.8796, 0.8925]\n",
            "F1        : 0.8857  0.0034\n",
            "          95% CI: [0.8796, 0.8923]\n",
            "ROC_AUC   : 0.9404  0.0018\n",
            "          95% CI: [0.9369, 0.9436]\n",
            "\n",
            "----- SVC -----\n",
            "ACCURACY  : 0.9791  0.0014\n",
            "          95% CI: [0.9764, 0.9818]\n",
            "PRECISION : 0.9791  0.0014\n",
            "          95% CI: [0.9765, 0.9818]\n",
            "RECALL    : 0.9791  0.0014\n",
            "          95% CI: [0.9764, 0.9818]\n",
            "F1        : 0.9791  0.0014\n",
            "          95% CI: [0.9764, 0.9817]\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store bootstrap results\n",
        "bootstrap_results = {}\n",
        "\n",
        "# Evaluate each model with bootstrapping\n",
        "for name, model in models.items():  # using your tuned models dictionary\n",
        "    print(f\"\\nRunning bootstrap evaluation for {name}...\")\n",
        "    bootstrap_results[name] = bootstrap_evaluation(model, X_test, y_test, n_iterations=100)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n================ Bootstrap Evaluation Results ================\")\n",
        "for model_name, metrics in bootstrap_results.items():\n",
        "    print(f\"\\n----- {model_name} -----\")\n",
        "    for metric, stats in metrics.items():\n",
        "        print(f\"{metric.upper():<10}: {stats['mean']:.4f}  {stats['std']:.4f}\")\n",
        "        print(f\"          95% CI: [{stats['ci_lower']:.4f}, {stats['ci_upper']:.4f}]\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}